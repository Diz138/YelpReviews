{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mounting drive"
      ],
      "metadata": {
        "id": "L877VDlli8BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbwpyE1Dix-6",
        "outputId": "a859e190-87f7-48a0-f1be-ad24027dbc57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing packages"
      ],
      "metadata": {
        "id": "ZYHz2fZahTSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from nltk.corpus import stopwords \n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "import re\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jb0mtO9hV2Q",
        "outputId": "eec3a889-f9d9-4e68-d53a-306df65ae07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading in dataset"
      ],
      "metadata": {
        "id": "fpZnt3Uthq0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/drive/MyDrive/WPI/Senior Year/NLP/CS525/yelp_food_reviews.pkl'\n",
        "df = pd.read_pickle(directory)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OgEcqxifhtI8",
        "outputId": "bfa48964-6a90-4a42-cdc6-4380521c3c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              business_id  stars  useful  funny  cool  \\\n",
              "0  XQfwVwDr-v0ZS3_CbbE5Xw    3.0       0      0     0   \n",
              "3  kxX2SOes4o-D3ZQBkiMRfA    5.0       1      0     1   \n",
              "5  04UD14gamNjLY0IDYVhHJg    1.0       1      2     1   \n",
              "7  LHSTtnW3YHCeUkRDGyJOyw    5.0       2      0     0   \n",
              "9  gebiRewfieSdtt17PTW6Zg    3.0       0      0     0   \n",
              "\n",
              "                                                text  visits  \\\n",
              "0  If you decide to eat here, just be aware it is...   177.0   \n",
              "3  Wow!  Yummy, different,  delicious.   Our favo...   204.0   \n",
              "5  I am a long term frequent customer of this est...   290.0   \n",
              "7  Amazingly amazing wings and homemade bleu chee...    84.0   \n",
              "9  Had a party of 6 here for hibachi. Our waitres...  1050.0   \n",
              "\n",
              "   visits_normalized  label  \n",
              "0          35.400000    1.0  \n",
              "3          18.545455    1.0  \n",
              "5          24.166667    1.0  \n",
              "7          12.000000    0.0  \n",
              "9          87.500000    2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdeec49d-8ae7-4464-9822-326220d1a97e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>text</th>\n",
              "      <th>visits</th>\n",
              "      <th>visits_normalized</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>If you decide to eat here, just be aware it is...</td>\n",
              "      <td>177.0</td>\n",
              "      <td>35.400000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
              "      <td>204.0</td>\n",
              "      <td>18.545455</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>04UD14gamNjLY0IDYVhHJg</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>I am a long term frequent customer of this est...</td>\n",
              "      <td>290.0</td>\n",
              "      <td>24.166667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LHSTtnW3YHCeUkRDGyJOyw</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Amazingly amazing wings and homemade bleu chee...</td>\n",
              "      <td>84.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>gebiRewfieSdtt17PTW6Zg</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Had a party of 6 here for hibachi. Our waitres...</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>87.500000</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdeec49d-8ae7-4464-9822-326220d1a97e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdeec49d-8ae7-4464-9822-326220d1a97e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdeec49d-8ae7-4464-9822-326220d1a97e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment(val):\n",
        "  if val >= 3:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "Y_nu9EYG2K3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using only a subset"
      ],
      "metadata": {
        "id": "B5QNy1iMjiYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset = df[['text','stars']].sample(n=10000, random_state=8)\n",
        "subset['stars'] = subset['stars'].apply(lambda x: sentiment(x))\n",
        "subset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vOggCJqrjhS5",
        "outputId": "ab679647-f899-4f87-dc71-37f3effae23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      text  stars\n",
              "4926291  My husband & I LOVE Old Castle. It's one of ou...      1\n",
              "6032203  Loved it here! The food was so delicious, lite...      1\n",
              "1243368  Take out order for dinner with family tonight,...      1\n",
              "2410403  Went for a simple steak dinner with a business...      1\n",
              "5174983  Had a very disappointing experience at Trailhe...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d0e8809-ddd2-4807-af0c-fdb5d438004e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4926291</th>\n",
              "      <td>My husband &amp; I LOVE Old Castle. It's one of ou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6032203</th>\n",
              "      <td>Loved it here! The food was so delicious, lite...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1243368</th>\n",
              "      <td>Take out order for dinner with family tonight,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2410403</th>\n",
              "      <td>Went for a simple steak dinner with a business...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5174983</th>\n",
              "      <td>Had a very disappointing experience at Trailhe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d0e8809-ddd2-4807-af0c-fdb5d438004e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d0e8809-ddd2-4807-af0c-fdb5d438004e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d0e8809-ddd2-4807-af0c-fdb5d438004e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting into training and testing"
      ],
      "metadata": {
        "id": "F_p_VAvzkP2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = subset['text'].values, subset['stars'].values\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\n",
        "print(f'shape of train data is {x_train.shape}')\n",
        "print(f'shape of test data is {x_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuLXEAJMkRqx",
        "outputId": "c8792782-cc04-49be-ca59-435cde711644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train data is (7500,)\n",
            "shape of test data is (2500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counts of each star"
      ],
      "metadata": {
        "id": "YQNwSn-wkzte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(y_train).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dt1nzRRmkwk",
        "outputId": "355003b9-5a13-450a-e8ea-3d88d25e34c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5931\n",
              "0    1569\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.Series(y_train).value_counts()\n",
        "sns.barplot(x=np.array([1,0]),y=dd.values)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "N0ga0WZSk767",
        "outputId": "aaf37ca7-2eeb-482f-c527-b984747ee43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Review Preprocessing"
      ],
      "metadata": {
        "id": "k3inUFuamyHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_string(s):\n",
        "    # Remove all non-word characters (everything except numbers and letters)\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    # Replace all runs of whitespaces with no space\n",
        "    s = re.sub(r\"\\s+\", '', s)\n",
        "    # replace digits with no space\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "\n",
        "    return s\n",
        "\n",
        "def tockenize(x_train,y_train,x_val,y_val):\n",
        "    word_list = []\n",
        "\n",
        "    stop_words = set(stopwords.words('english')) \n",
        "    for sent in x_train:\n",
        "        for word in sent.lower().split():\n",
        "            word = preprocess_string(word)\n",
        "            if word not in stop_words and word != '':\n",
        "                word_list.append(word)\n",
        "  \n",
        "    corpus = Counter(word_list)\n",
        "    # sorting on the basis of most common words\n",
        "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:len(word_list)]\n",
        "    # creating a dict\n",
        "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
        "    \n",
        "    # tockenize\n",
        "    final_list_train,final_list_test = [],[]\n",
        "    for sent in x_train:\n",
        "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
        "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
        "    for sent in x_val:\n",
        "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
        "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
        "            \n",
        "    #encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n",
        "    #encoded_test = [1 if label =='positive' else 0 for label in y_val] \n",
        "    return np.array(final_list_train), np.array(y_train),np.array(final_list_test), np.array(y_test), onehot_dict"
      ],
      "metadata": {
        "id": "5LrAwUUYlGZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8iWO9CAlLzD",
        "outputId": "80f4206f-2eee-4679-de4b-e404244e1890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-34e8be5549ef>:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(final_list_train), np.array(y_train),np.array(final_list_test), np.array(y_test), onehot_dict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Length of vocabulary is {len(vocab)}')\n",
        "print(type(x_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HhNhKSdnmZK",
        "outputId": "45f98988-7de6-4451-efce-f2957006dbba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of vocabulary is 22466\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzing review length\n"
      ],
      "metadata": {
        "id": "B8ffPseUoR6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rev_len = [len(i) for i in x_train]\n",
        "pd.Series(rev_len).hist()\n",
        "plt.show()\n",
        "pd.Series(rev_len).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "kBFNcTQqoVLf",
        "outputId": "e874acf1-3962-4dcd-cd55-752156c8e71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    7500.000000\n",
              "mean       51.765467\n",
              "std        46.356628\n",
              "min         1.000000\n",
              "25%        22.000000\n",
              "50%        37.000000\n",
              "75%        66.000000\n",
              "max       446.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Padding"
      ],
      "metadata": {
        "id": "92DztSBcoZy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "    return features"
      ],
      "metadata": {
        "id": "JzGFOESsoXsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_pad = padding_(x_train,500)\n",
        "x_test_pad = padding_(x_test,500)"
      ],
      "metadata": {
        "id": "SZGfZ2vLohEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train_pad[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_VLeG3ngN5d",
        "outputId": "0e5cc1eb-e2a3-4e18-b0dd-ed33e91f873d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batching and loading as Tensor for TensorFlow"
      ],
      "metadata": {
        "id": "0rKB7LCDonHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
        "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "gtFxLVw6oqli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLD5IlJdn0dh",
        "outputId": "8a79137a-f53c-49c2-cbfa-f410ab99412f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([500])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RatingRNN(nn.Module):\n",
        "    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n",
        "        super(RatingRNN,self).__init__()\n",
        " \n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        " \n",
        "        self.no_layers = no_layers\n",
        "        self.vocab_size = vocab_size\n",
        "    \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        #lstm\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
        "                           num_layers=no_layers, batch_first=True)\n",
        "          # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "    \n",
        "        # linear and sigmoid layer\n",
        "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self,x,hidden):\n",
        "          batch_size = x.size(0)\n",
        "          # embeddings and lstm_out\n",
        "          embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
        "          #print(embeds.shape)  #[50, 500, 1000]\n",
        "          lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        \n",
        "          lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n",
        "        \n",
        "          # dropout and fully connected layer\n",
        "          out = self.dropout(lstm_out)\n",
        "          out = self.fc(out)\n",
        "        \n",
        "          # sigmoid function\n",
        "          sig_out = self.sig(out)\n",
        "        \n",
        "          # reshape to be batch_size first\n",
        "          sig_out = sig_out.view(batch_size, -1)\n",
        "\n",
        "          sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "          # return last sigmoid output and hidden state\n",
        "          return sig_out, hidden\n",
        "    def init_hidden(self, batch_size):\n",
        "          ''' Initializes hidden state '''\n",
        "          # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "          # initialized to zero, for hidden state and cell state of LSTM\n",
        "          h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim))\n",
        "          c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim))\n",
        "          hidden = (h0,c0)\n",
        "          return hidden\n",
        "\n",
        "\n",
        "      "
      ],
      "metadata": {
        "id": "uY0PmUfUo2Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_layers = 2\n",
        "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
        "embedding_dim = 64\n",
        "output_dim = 1\n",
        "hidden_dim = 256\n",
        "\n",
        "\n",
        "model = RatingRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n",
        "\n",
        "#moving to gpu\n",
        "#model.to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwsoD3cGrJ0m",
        "outputId": "9d436113-a558-428f-c527-fcfdddcc93a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RatingRNN(\n",
            "  (embedding): Embedding(22126, 64)\n",
            "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# function to predict accuracy\n",
        "def acc(pred,label):\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item()"
      ],
      "metadata": {
        "id": "-wO32ctdrVYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 5\n",
        "epochs = 5 \n",
        "valid_loss_min = np.Inf\n",
        "# train for some number of epochs\n",
        "epoch_tr_loss,epoch_vl_loss = [],[]\n",
        "epoch_tr_acc,epoch_vl_acc = [],[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    # initialize hidden state \n",
        "    h = model.init_hidden(batch_size)\n",
        "    for inputs, labels in train_loader:\n",
        "        \n",
        "        inputs, labels = inputs, labels \n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "        print(inputs)\n",
        "        model.zero_grad()\n",
        "        output,h = model(inputs,h)\n",
        "        \n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        train_losses.append(loss.item())\n",
        "        # calculating accuracy\n",
        "        accuracy = acc(output,labels)\n",
        "        train_acc += accuracy\n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        " \n",
        "    \n",
        "        \n",
        "    val_h = model.init_hidden(batch_size)\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    model.eval()\n",
        "    for inputs, labels in valid_loader:\n",
        "            val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "            inputs, labels = inputs, labels\n",
        "\n",
        "            output, val_h = model(inputs, val_h)\n",
        "            val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "            val_losses.append(val_loss.item())\n",
        "            \n",
        "            accuracy = acc(output,labels)\n",
        "            val_acc += accuracy\n",
        "            \n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch+1}') \n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
        "    if epoch_val_loss <= valid_loss_min:\n",
        "        torch.save(model.state_dict(), 'state_dict.pt')\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
        "        valid_loss_min = epoch_val_loss\n",
        "    print(25*'==')"
      ],
      "metadata": {
        "id": "4l6Xi1LTrdqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac127d58-06cf-4342-b934-674640eb7d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     0,     0,  ...,   222,    34,     9],\n",
            "        [    0,     0,     0,  ...,  1723,  7194,    25],\n",
            "        [    0,     0,     0,  ...,   135,    24,   102],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ...,   790,   485,    81],\n",
            "        [    0,     0,     0,  ...,   110, 17375,  1369],\n",
            "        [    0,     0,     0,  ...,   515,   325,   706]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vdrh39n4rvwH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}